{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860f6415-e8a3-48f8-bdcc-1e66b1aa0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra_data import RunDirectory \n",
    "import h5py \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "PREFIX='/gpfs/exfel/exp/SPB/202202/p003046'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bd723-600b-45de-8f6a-797c5c01fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray\n",
    "import scipy.optimize\n",
    "from scipy import signal\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the default theme\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2019704-11b7-4063-b994-29a537674b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "read_cache = {}\n",
    "\n",
    "def read_run_sync_trains(r, verbose=True, cache=True, use_cache=True):\n",
    "    global read_cache\n",
    "    if r in read_cache and use_cache:\n",
    "        return read_cache[r]\n",
    "    #clear_output(wait=False) \n",
    "    #sys.stderr.write(f'Processing run {r}...\\n') \n",
    "    run = RunDirectory(path='/pnfs/xfel.eu/exfel/archive/XFEL/raw/SPB/202202/p003046/r%04d' % (r))  \n",
    "    \n",
    "    # The require_all=True ensures we only get trains which exist for all sources\n",
    "    sel = run.select([\n",
    "        ('SPB_XTD9_XGM/XGM/DOOCS:output', 'data.intensitySa1TD'),\n",
    "        ('SA1_XTD2_XGM/XGM/DOOCS:output', 'data.intensitySa1TD'),\n",
    "        ('SPB_IRU_MOTORS/MDL/DATA_SELECT', '*'),\n",
    "        ('SPB_EXP_ZYLA/CAM/1:daqOutput', 'data.image.pixels'),\n",
    "    ], require_all=True)\n",
    "    if(verbose):\n",
    "        sel.info()\n",
    "    \n",
    "    intensity_sase1_extra = sel['SPB_XTD9_XGM/XGM/DOOCS:output', 'data.intensitySa1TD']\n",
    "    intensity_preattenuator_sase1_extra = sel['SA1_XTD2_XGM/XGM/DOOCS:output', 'data.intensitySa1TD']    \n",
    "    motors_x_extra = sel['SPB_IRU_MOTORS/MDL/DATA_SELECT', 'SPB_IRU_INJMOV_MOTOR_X.actualPosition.value']\n",
    "    motors_y_extra = sel['SPB_IRU_MOTORS/MDL/DATA_SELECT', 'SPB_IRU_INJMOV_MOTOR_Y.actualPosition.value']\n",
    "    sidemic_extra = sel['SPB_EXP_ZYLA/CAM/1:daqOutput', 'data.image.pixels']\n",
    "\n",
    "    # Put the data in xarray\n",
    "    motor_x = motors_x_extra.xarray()\n",
    "    motor_y = motors_y_extra.xarray()\n",
    "    xgm = intensity_sase1_extra.xarray()\n",
    "    xgm2 = intensity_preattenuator_sase1_extra.xarray()\n",
    "    sidemic = sidemic_extra.xarray()\n",
    "    \n",
    "    directory = '/gpfs/exfel/u/scratch/SPB/202202/p003046/data' \n",
    "    agipd_frames_per_train = 202 # number of agipd frames per train\n",
    "    with h5py.File(directory+'/r%04d_proc_radavg.h5' % (r)) as rad: \n",
    "        radavg = rad['entry_1']['radialavg'][:]\n",
    "        trainIds = rad['entry_1']['trainId'][:]\n",
    "        radcount = rad['entry_1']['radialcount'][:]\n",
    "        q = rad['entry_1']['q'][:]\n",
    "\n",
    "    with h5py.File(directory+'/r%04d_proc_laser.h5' % (r)) as rad: \n",
    "        laser_on = rad['entry_1']['laser_on'][:]\n",
    "        trainIds_laser = rad['entry_1']['trainId'][:]\n",
    "        \n",
    " \n",
    "        \n",
    "    # Reshape the arrays from the radavg file to make them by train\n",
    "    radavg = radavg.reshape((-1,agipd_frames_per_train,radavg.shape[1]))\n",
    "    radcount = radcount.reshape((-1,agipd_frames_per_train,radcount.shape[1]))\n",
    "    trainIds = trainIds.reshape((-1,agipd_frames_per_train))\n",
    "    \n",
    "    # Ensure all the trains are the same length\n",
    "    if (trainIds == trainIds[:,:1]).all() != True:\n",
    "        raise ValueError        \n",
    "    if(verbose):\n",
    "        print(\"Reshaping of radavg successful:\", (trainIds == trainIds[:,:1]).all())\n",
    "    trainIds = trainIds[:,0]\n",
    "    \n",
    "    # Put radavg in an xarray\n",
    "    radavg = xarray.DataArray(data=radavg, dims=('trainId', 'pulseNr', 'q'), \n",
    "                              coords={'trainId': trainIds, 'pulseNr': np.arange(agipd_frames_per_train), 'q': q})\n",
    "    radcount = xarray.DataArray(data=radcount, dims=('trainId', 'pulseNr', 'q'), \n",
    "                              coords={'trainId': trainIds, 'pulseNr': np.arange(agipd_frames_per_train), 'q': q})\n",
    "    \n",
    "    # Put laser_on in an xarray\n",
    "    laser = xarray.DataArray(data=laser_on, dims=('trainId'), \n",
    "                              coords={'trainId': trainIds_laser})\n",
    "\n",
    "    # Find trains which are common between radavg and the rest\n",
    "    common_trains = np.intersect1d(intensity_sase1_extra.train_id_coordinates(), np.intersect1d(trainIds, trainIds_laser))\n",
    "    if verbose:\n",
    "        print(\"Found %d common train IDs between radavg and the rest\" % len(common_trains))\n",
    "\n",
    "    # Find the indices of the common trainIds and keep only those\n",
    "    common_train_idx = np.searchsorted(intensity_sase1_extra.train_id_coordinates(),common_trains)\n",
    "    motor_x = motor_x[common_train_idx]\n",
    "    motor_y = motor_y[common_train_idx]\n",
    "    xgm = xgm[common_train_idx]\n",
    "\n",
    "    # Find the indices of the common trainIds for radavg    \n",
    "    common_train_idx = np.searchsorted(radavg.coords['trainId'].data,common_trains)\n",
    "    radavg = radavg[common_train_idx]\n",
    "    radcount = radcount[common_train_idx]\n",
    "\n",
    "    # Find the indices of the common trainIds for laser_on    \n",
    "    common_train_idx = np.searchsorted(laser.coords['trainId'].data,common_trains)\n",
    "    laser = laser[common_train_idx]\n",
    "    \n",
    "    train_ids_eq = (motor_x.coords['trainId'].data == radavg.coords['trainId'].data) * (motor_x.coords['trainId'].data == laser.coords['trainId'].data)\n",
    "    if verbose:\n",
    "        print(\"Train IDs all match:\", train_ids_eq.all())\n",
    "    if(cache):\n",
    "        read_cache[r] = (xgm, motor_x, motor_y, radavg, xgm2, sidemic, laser, radcount)\n",
    "    return xgm, motor_x, motor_y, radavg, xgm2, sidemic, laser, radcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_run(run, corr_thres = 0.9995):\n",
    "    xgm, motor_x, motor_y, radavg, xgm2, sidemic, laser, radcount = read_run_sync_trains(run, verbose=False)\n",
    "    good_pulses = np.zeros(radavg.shape[1], dtype=bool)\n",
    "    good_pulses[1:176] = True    \n",
    "    if(corr_thres is not None):\n",
    "        radavg_train = np.nanmean(radavg[:,good_pulses,:],axis=(1))\n",
    "        radavg_train[np.isnan(radavg_train)] = 0\n",
    "        all_corr = np.corrcoef(radavg_train.astype('float'))\n",
    "        good_trains = np.mean(all_corr,axis=1) > corr_thres\n",
    "        print(\"Kept %d out of %d trains\" % (good_trains.sum(), len(good_trains)))\n",
    "    else:\n",
    "        good_trains = np.ones(laser.shape, dtype=bool)\n",
    "        \n",
    "    # good trains go from the train before the first laser to the last laser\n",
    "    if(not laser[0]):\n",
    "        good_trains[:np.nonzero(laser.data==True)[0][0]-1] = 0\n",
    "    if(not laser[-1]):\n",
    "        good_trains[np.nonzero(laser.data==True)[0][-1]+1:] = 0\n",
    "    print(\"Kept %d out of %d trains\" % (good_trains.sum(), len(good_trains)))\n",
    "    return radavg, radcount, laser, good_trains, good_pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64950a-c07b-4122-9b1d-6e1a43dd3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_floor(run, figure=None, show_noise=True, corr_thres = None, norm_q_range = None, pixel_count_norm=True):\n",
    "    radavg, radcount, laser, good_trains, good_pulses = filtered_run(run, corr_thres = corr_thres)        \n",
    "\n",
    "    laser_off = (laser == False)*good_trains\n",
    "    laser_on = (laser == True)*good_trains\n",
    "\n",
    "    q = radavg.coords['q'].data\n",
    "    \n",
    "    if norm_q_range is not None:\n",
    "        norm_q_slice = slice(np.argmax(q > norm_q_range[0]), np.argmax(q > norm_q_range[1]))    \n",
    "    else:\n",
    "        norm_q_slice = slice(None,None)\n",
    "        \n",
    "    print(\"Normalization slice - \",norm_q_slice)\n",
    "        \n",
    "    if figure is None:\n",
    "        plt.figure(figsize=(12,4))    \n",
    "    \n",
    "    laser_off_per_q = np.nanmean(radavg[(laser == False)*good_trains,good_pulses],axis=(0,1))\n",
    "    if(pixel_count_norm):        \n",
    "        pixel_count_factor = radcount[0,0]/np.nanmean(radcount[0,0])\n",
    "    else:\n",
    "        pixel_count_factor = 1\n",
    "    laser_off_I = np.nansum((laser_off_per_q*pixel_count_factor)[norm_q_slice])\n",
    "    laser_on_q = np.nanmean(radavg[(laser == True)*good_trains,good_pulses],axis=(0,1))\n",
    "    laser_on_I = np.nansum((laser_on_q*pixel_count_factor)[norm_q_slice])\n",
    "    \n",
    "    laser_on_q_norm = laser_on_q/laser_on_I\n",
    "    laser_off_q_norm = laser_off_per_q/laser_off_I\n",
    "    \n",
    "    plt.plot(q, (laser_on_q_norm - laser_off_q_norm), label='Run %d Signal' % run)\n",
    "    plt.ylim([-5e-6,5e-6])\n",
    "    #ax2 = plt.gca().twinx()\n",
    "    #ax2.plot(q, laser_on_q_norm, label='Run %d Laser On' % run)\n",
    "    #ax2.plot(q, laser_off_q_norm, label='Run %d Laser Off' % run)\n",
    "    #ax2.plot(q, radcount[0,0]/1000000, label='MPixels per q')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "    plt.tight_layout()    \n",
    "    return q, laser_on_q_norm, laser_off_q_norm, good_trains.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd71f9e-56f3-4895-b0c1-d9708c2e511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_buffer_runs(error_thres = 1e-4, corr_thres=0.99995):\n",
    "    all_buffer_runs = 133,135,141,142,146,156,160\n",
    "    fig = plt.figure(figsize=(12,4)) \n",
    "    good_runs = []\n",
    "    for run in all_buffer_runs:\n",
    "        q, laser_on_q_norm, laser_off_q_norm, good_trains = noise_floor(run, figure=fig, show_noise=False, corr_thres=corr_thres)\n",
    "        mean_error = np.nansum(np.abs(laser_on_q_norm-laser_off_q_norm))\n",
    "        if mean_error < error_thres:\n",
    "            good_runs.append(run)\n",
    "        print(run, mean_error)\n",
    "    return good_runs\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0f9ca-6c0e-4f76-b198-13749dce9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_buff(corr_thres=0.99995, cache=True, use_cache=True):\n",
    "    global read_cache\n",
    "    if 'I_buff' in read_cache and use_cache:\n",
    "        return read_cache['I_buff']\n",
    "    buffer_runs = good_buffer_runs(corr_thres=corr_thres)\n",
    "    I_buff = None\n",
    "    I_buff_count = None\n",
    "    shots = 0\n",
    "    for run in buffer_runs:\n",
    "        radavg, radcount, laser, good_trains, good_pulses = filtered_run(run, corr_thres = corr_thres)\n",
    "        q = radavg.coords['q'].data\n",
    "        shots += np.sum(good_trains)*np.sum(good_pulses)\n",
    "        if I_buff is None:\n",
    "            I_buff = np.nansum(radavg[good_trains,good_pulses],axis=(0,1))\n",
    "            I_buff_count = np.nansum(radcount[good_trains,good_pulses],axis=(0,1))\n",
    "        else:\n",
    "            I_buff += np.nansum(radavg[good_trains,good_pulses],axis=(0,1))\n",
    "            I_buff_count += np.nansum(radcount[good_trains,good_pulses],axis=(0,1))\n",
    "    I_buff /= shots\n",
    "    I_buff_count /= shots\n",
    "    if cache:\n",
    "        read_cache['I_buff'] = I_buff\n",
    "    return I_buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0dde4-e5e9-48e5-8ec2-187ef94424e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_I_buff(I):\n",
    "    import scipy.optimize\n",
    "    scipy.optimize.minimize_scalar\n",
    "    if (I.ndim > 1):\n",
    "        Ip = np.zeros_like(I)\n",
    "        for p in range(I.shape[0]):\n",
    "            res = scipy.optimize.minimize_scalar(lambda x: np.nansum(np.abs(x*I[p]-I_buff())))\n",
    "            Ip[p] = I[p]*res.x-I_buff()\n",
    "    else:\n",
    "        res = scipy.optimize.minimize_scalar(lambda x: np.nansum(np.abs(x*I-I_buff())))\n",
    "        Ip = I*res.x-I_buff()        \n",
    "    return Ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f510b1db-2444-4c2c-87d3-51af2cf1591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def I_on_off(runs, corr_thres=0.99995):\n",
    "    I_on = None\n",
    "    I_on_count = None\n",
    "    I_off = None\n",
    "    I_off_count = None    \n",
    "    shots_on = 0\n",
    "    shots_off = 0\n",
    "    for run in runs:\n",
    "        radavg, radcount, laser, good_trains, good_pulses = filtered_run(run, corr_thres = corr_thres)\n",
    "        # Don't take runs with less than 75% good trains\n",
    "        if np.nanmean(good_trains) < 0.75:\n",
    "            continue\n",
    "        q = radavg.coords['q'].data\n",
    "        \n",
    "        shots_off += np.sum((laser.data == False)*good_trains)*np.sum(good_pulses)\n",
    "        shots_on += np.sum((laser.data == True)*good_trains)*np.sum(good_pulses)\n",
    "        if I_off is None:\n",
    "            I_off = np.nansum(radavg[(laser == False)*good_trains,good_pulses],axis=(0))\n",
    "            I_off_count = np.nansum(radcount[(laser == False)*good_trains,good_pulses],axis=(0))\n",
    "            \n",
    "            I_on = np.nanmean(radavg[(laser == True)*good_trains,good_pulses],axis=(0))            \n",
    "            I_on_count = np.nansum(radcount[(laser == True)*good_trains,good_pulses],axis=(0))\n",
    "        else:\n",
    "            I_off += np.nansum(radavg[(laser == False)*good_trains,good_pulses],axis=(0))\n",
    "            I_off_count += np.nansum(radcount[(laser == False)*good_trains,good_pulses],axis=(0))\n",
    "            I_on += np.nanmean(radavg[(laser == True)*good_trains,good_pulses],axis=(0))            \n",
    "            I_on_count += np.nansum(radcount[(laser == True)*good_trains,good_pulses],axis=(0))\n",
    "    I_off /= shots_off\n",
    "    I_on /= shots_on\n",
    "    I_off_count /= shots_off\n",
    "    I_on_count /= shots_on\n",
    "    return I_on, I_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_on, I_off = I_on_off(np.arange(167, 168))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7893b-7688-4349-a1ab-648068c93381",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_on, I_off = I_on_off(np.arange(167, 181))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025cbea-a31e-4b38-9efd-94573e399db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(None)\n",
    "plt.imshow(remove_I_buff(I_on)-remove_I_buff(I_off), vmax=1,vmin=-1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6832991-26ca-4eb0-a96c-601fb68c142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"runs_167-180_I_pon-I_poff.csv\", remove_I_buff(I_on)-remove_I_buff(I_off), delimiter=\",\")\n",
    "np.savetxt(\"runs_167-180_I_poff.csv\", remove_I_buff(I_off), delimiter=\",\")\n",
    "np.savetxt(\"runs_167-180_I_pon.csv\", remove_I_buff(I_on), delimiter=\",\")\n",
    "np.savetxt(\"runs_167-180_I_off.csv\", I_off, delimiter=\",\")\n",
    "np.savetxt(\"runs_167-180_I_on.csv\", I_on, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b50916-7847-4509-bd23-7a6b75307183",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_on, I_off = I_on_off([136, 137, 138, 139, 140, 149, 150, 151, 152, 155, 157, 158, 164, 165])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29cbf68-a38a-44cf-8fa0-f989812f2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.grid(None)\n",
    "plt.imshow(remove_I_buff(I_on)-remove_I_buff(I_off), vmax=1,vmin=-1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b2ecb-7dbf-49ce-aec4-2774fc6dfaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"runs_136-165_I_pon-I_poff.csv\", remove_I_buff(I_on)-remove_I_buff(I_off), delimiter=\",\")\n",
    "np.savetxt(\"runs_136-165_I_poff.csv\", remove_I_buff(I_off), delimiter=\",\")\n",
    "np.savetxt(\"runs_136-165_I_pon.csv\", remove_I_buff(I_on), delimiter=\",\")\n",
    "np.savetxt(\"runs_136-165_I_off.csv\", I_off, delimiter=\",\")\n",
    "np.savetxt(\"runs_136-165_I_on.csv\", I_on, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7d029-6e5a-4686-bc4d-fe29f831618d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfel (current)",
   "language": "python",
   "name": "xfel-current"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
